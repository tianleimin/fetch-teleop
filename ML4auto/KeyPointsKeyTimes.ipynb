{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1226e595",
   "metadata": {},
   "source": [
    "### extract time steps 5 seconds before the robot started driving to participants and 5 seconds before the robot started reaching out its arm to capture the \"start gesture\" for OTP classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0a0c9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "41a76c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract key time segments\n",
    "def keytime(df):\n",
    "    # find when df['base status'] changes\n",
    "    current_base = df['base status'].values[1:]\n",
    "    previous_base = df['base status'].values[:-1]\n",
    "    base_change = current_base != previous_base\n",
    "    # find when df['arm status'] changes\n",
    "    current_arm = df['arm status'].values[1:]\n",
    "    previous_arm = df['arm status'].values[:-1]\n",
    "    arm_change = current_arm != previous_arm\n",
    "\n",
    "    # robot moving to participant (start the episode)\n",
    "    to_participant = current_base == 'TO PARTICIPANT'\n",
    "    # robot reaching out arm (start the object exchange)\n",
    "    arm_reaching = current_arm == 'REACHING'\n",
    "    # only look at object exchange at participant side\n",
    "    current_status = df['status'].values[1:]\n",
    "    p_handover = current_status != 'OPERATOR HANDOVER'\n",
    "\n",
    "    # get data 5s before the key changes in base and arm status\n",
    "    buffer = 50\n",
    "    ends_base = np.where(base_change & to_participant)[0]\n",
    "    starts_base = ends_base - buffer\n",
    "    ends_arm = np.where(arm_change & arm_reaching & p_handover)[0]\n",
    "    starts_arm = ends_arm - buffer\n",
    "\n",
    "    idx_base = np.array([list(range(start_base,end_base)) for start_base, end_base in zip(starts_base, ends_base)]).flatten()\n",
    "    idx_arm = np.array([list(range(start_arm,end_arm)) for start_arm, end_arm in zip(starts_arm, ends_arm)]).flatten()\n",
    "    idx = np.concatenate((idx_base,idx_arm))\n",
    "    idx.sort(kind='mergesort')\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "be202d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing participant: p1_2022-07-25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda\\envs\\handover_ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3552: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing participant: p2_2022-08-03\n",
      "Finished processing participant: p3_2022-08-04\n",
      "Finished processing participant: p4_2022-08-10\n",
      "Finished processing participant: p5_2022-08-12\n",
      "Finished processing participant: p6_2022-08-15\n",
      "Finished processing participant: p7_2022-08-15\n",
      "Finished processing participant: p8_2022-08-19\n",
      "Finished processing participant: p9_2022-08-22\n",
      "Finished processing participant: p10_2022-08-26\n",
      "Finished processing participant: p11_2022-08-29\n",
      "Finished processing participant: p12_2022-08-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\Anaconda\\envs\\handover_ML\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3552: DtypeWarning: Columns (3,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing participant: p13_2022-08-29\n",
      "Finished processing participant: p14_2022-08-31\n",
      "Finished processing participant: p15_2022-09-02\n",
      "Finished processing participant: p16_2022-09-05\n",
      "Finished processing participant: p17_2022-09-06\n",
      "Finished processing participant: p18_2022-09-07\n",
      "Finished processing participant: p19_2022-09-08\n",
      "Finished processing participant: p20_2022-09-09\n"
     ]
    }
   ],
   "source": [
    "# data type of columns\n",
    "int_cols = ['episode']\n",
    "cat_cols = ['status', 'handover quality', 'handover type', 'arm status', 'base status', 'handover status']\n",
    "\n",
    "# load raw data\n",
    "participants = ['p1_2022-07-25', 'p2_2022-08-03', 'p3_2022-08-04', 'p4_2022-08-10', 'p5_2022-08-12', \n",
    "                'p6_2022-08-15', 'p7_2022-08-15', 'p8_2022-08-19', 'p9_2022-08-22', 'p10_2022-08-26', \n",
    "                'p11_2022-08-29', 'p12_2022-08-29', 'p13_2022-08-29', 'p14_2022-08-31', 'p15_2022-09-02', \n",
    "                'p16_2022-09-05', 'p17_2022-09-06', 'p18_2022-09-07', 'p19_2022-09-08', 'p20_2022-09-09']\n",
    "\n",
    "for participant in participants:\n",
    "    raw_data = 'data/ML/' + participant\n",
    "\n",
    "    # read csv into dataframe\n",
    "    df = pd.read_csv((raw_data + '.csv'), header = 0)\n",
    "    # specific data type of columns\n",
    "    for column in df:\n",
    "        if column in int_cols:\n",
    "            df[column] = df[column].astype('int')\n",
    "        elif column in cat_cols:\n",
    "            df[column] = df[column].astype('category')\n",
    "        else:\n",
    "            df[column] = df[column].astype('float')\n",
    "\n",
    "    # fill missing values in the manually entered handover quality and type columns\n",
    "    df['handover quality'] = df['handover quality'].cat.add_categories('NEUTRAL')\n",
    "    df['handover quality'].fillna('NEUTRAL', inplace =True)\n",
    "    #df['handover type'] = df['handover type'].cat.add_categories('NEITHER')\n",
    "    #df['handover type'].fillna('NEITHER', inplace =True) \n",
    "    df['handover type'].fillna('ROBOT TO HUMAN', inplace =True)\n",
    "    \n",
    "    # extract key segments\n",
    "    idx = keytime(df)\n",
    "    # save as new data files\n",
    "    df.iloc[idx].to_csv((raw_data + '_keytime.csv'), index=False)\n",
    "    \n",
    "    print(f'Finished processing participant: {participant}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "08a2453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create concatenated files for 5-fold cv and train-dev segmentation\n",
    "def combcsv(segment, cv, mode):\n",
    "    # list of processed df \n",
    "    list_comb = []\n",
    "    # name of combined dataset file\n",
    "    combined_csv = 'data/ML/combined_' + mode +'_' + cv + '.csv'\n",
    "    # concatenate\n",
    "    for participant in segment:\n",
    "        proc_data_each = 'data/ML/' + participant + '_' + mode + '.csv'\n",
    "        df_each = pd.read_csv(proc_data_each, header = 0)\n",
    "        list_comb.append(df_each)\n",
    "        print('Read processed data:', participant)\n",
    "    print('Concatenating...')\n",
    "    df_comb = pd.concat(list_comb)\n",
    "    print('Saving concatenated dataset...')\n",
    "    df_comb.to_csv(combined_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ed75a090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read processed data: p2_2022-08-03\n",
      "Read processed data: p3_2022-08-04\n",
      "Read processed data: p4_2022-08-10\n",
      "Read processed data: p6_2022-08-15\n",
      "Read processed data: p7_2022-08-15\n",
      "Read processed data: p8_2022-08-19\n",
      "Read processed data: p10_2022-08-26\n",
      "Read processed data: p11_2022-08-29\n",
      "Read processed data: p12_2022-08-29\n",
      "Read processed data: p14_2022-08-31\n",
      "Read processed data: p15_2022-09-02\n",
      "Read processed data: p16_2022-09-05\n",
      "Read processed data: p18_2022-09-07\n",
      "Read processed data: p19_2022-09-08\n",
      "Read processed data: p20_2022-09-09\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p1_2022-07-25\n",
      "Read processed data: p5_2022-08-12\n",
      "Read processed data: p9_2022-08-22\n",
      "Read processed data: p13_2022-08-29\n",
      "Read processed data: p17_2022-09-06\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p5_2022-08-12\n",
      "Read processed data: p6_2022-08-15\n",
      "Read processed data: p7_2022-08-15\n",
      "Read processed data: p8_2022-08-19\n",
      "Read processed data: p9_2022-08-22\n",
      "Read processed data: p10_2022-08-26\n",
      "Read processed data: p11_2022-08-29\n",
      "Read processed data: p12_2022-08-29\n",
      "Read processed data: p13_2022-08-29\n",
      "Read processed data: p14_2022-08-31\n",
      "Read processed data: p15_2022-09-02\n",
      "Read processed data: p16_2022-09-05\n",
      "Read processed data: p17_2022-09-06\n",
      "Read processed data: p18_2022-09-07\n",
      "Read processed data: p19_2022-09-08\n",
      "Read processed data: p20_2022-09-09\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p1_2022-07-25\n",
      "Read processed data: p2_2022-08-03\n",
      "Read processed data: p3_2022-08-04\n",
      "Read processed data: p4_2022-08-10\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p1_2022-07-25\n",
      "Read processed data: p2_2022-08-03\n",
      "Read processed data: p3_2022-08-04\n",
      "Read processed data: p4_2022-08-10\n",
      "Read processed data: p9_2022-08-22\n",
      "Read processed data: p10_2022-08-26\n",
      "Read processed data: p11_2022-08-29\n",
      "Read processed data: p12_2022-08-29\n",
      "Read processed data: p13_2022-08-29\n",
      "Read processed data: p14_2022-08-31\n",
      "Read processed data: p15_2022-09-02\n",
      "Read processed data: p16_2022-09-05\n",
      "Read processed data: p17_2022-09-06\n",
      "Read processed data: p18_2022-09-07\n",
      "Read processed data: p19_2022-09-08\n",
      "Read processed data: p20_2022-09-09\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p5_2022-08-12\n",
      "Read processed data: p6_2022-08-15\n",
      "Read processed data: p7_2022-08-15\n",
      "Read processed data: p8_2022-08-19\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p1_2022-07-25\n",
      "Read processed data: p2_2022-08-03\n",
      "Read processed data: p3_2022-08-04\n",
      "Read processed data: p4_2022-08-10\n",
      "Read processed data: p5_2022-08-12\n",
      "Read processed data: p6_2022-08-15\n",
      "Read processed data: p7_2022-08-15\n",
      "Read processed data: p8_2022-08-19\n",
      "Read processed data: p13_2022-08-29\n",
      "Read processed data: p14_2022-08-31\n",
      "Read processed data: p15_2022-09-02\n",
      "Read processed data: p16_2022-09-05\n",
      "Read processed data: p17_2022-09-06\n",
      "Read processed data: p18_2022-09-07\n",
      "Read processed data: p19_2022-09-08\n",
      "Read processed data: p20_2022-09-09\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p9_2022-08-22\n",
      "Read processed data: p10_2022-08-26\n",
      "Read processed data: p11_2022-08-29\n",
      "Read processed data: p12_2022-08-29\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p1_2022-07-25\n",
      "Read processed data: p2_2022-08-03\n",
      "Read processed data: p3_2022-08-04\n",
      "Read processed data: p4_2022-08-10\n",
      "Read processed data: p5_2022-08-12\n",
      "Read processed data: p6_2022-08-15\n",
      "Read processed data: p7_2022-08-15\n",
      "Read processed data: p8_2022-08-19\n",
      "Read processed data: p9_2022-08-22\n",
      "Read processed data: p10_2022-08-26\n",
      "Read processed data: p11_2022-08-29\n",
      "Read processed data: p12_2022-08-29\n",
      "Read processed data: p17_2022-09-06\n",
      "Read processed data: p18_2022-09-07\n",
      "Read processed data: p19_2022-09-08\n",
      "Read processed data: p20_2022-09-09\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p13_2022-08-29\n",
      "Read processed data: p14_2022-08-31\n",
      "Read processed data: p15_2022-09-02\n",
      "Read processed data: p16_2022-09-05\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p1_2022-07-25\n",
      "Read processed data: p2_2022-08-03\n",
      "Read processed data: p3_2022-08-04\n",
      "Read processed data: p4_2022-08-10\n",
      "Read processed data: p5_2022-08-12\n",
      "Read processed data: p6_2022-08-15\n",
      "Read processed data: p7_2022-08-15\n",
      "Read processed data: p8_2022-08-19\n",
      "Read processed data: p9_2022-08-22\n",
      "Read processed data: p10_2022-08-26\n",
      "Read processed data: p11_2022-08-29\n",
      "Read processed data: p12_2022-08-29\n",
      "Read processed data: p13_2022-08-29\n",
      "Read processed data: p14_2022-08-31\n",
      "Read processed data: p15_2022-09-02\n",
      "Read processed data: p16_2022-09-05\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n",
      "Read processed data: p17_2022-09-06\n",
      "Read processed data: p18_2022-09-07\n",
      "Read processed data: p19_2022-09-08\n",
      "Read processed data: p20_2022-09-09\n",
      "Concatenating...\n",
      "Saving concatenated dataset...\n"
     ]
    }
   ],
   "source": [
    "# tranining and development sets for parameter grid search\n",
    "ML_trn = ['p2_2022-08-03', 'p3_2022-08-04', 'p4_2022-08-10', \n",
    "          'p6_2022-08-15', 'p7_2022-08-15', 'p8_2022-08-19', 'p10_2022-08-26', \n",
    "          'p11_2022-08-29', 'p12_2022-08-29', 'p14_2022-08-31', 'p15_2022-09-02', \n",
    "          'p16_2022-09-05', 'p18_2022-09-07', 'p19_2022-09-08', 'p20_2022-09-09']\n",
    "ML_dev = ['p1_2022-07-25', 'p5_2022-08-12', 'p9_2022-08-22', 'p13_2022-08-29', 'p17_2022-09-06']\n",
    "\n",
    "# for 5-fold cross-validation experiments\n",
    "cv_1 = participants[0:4]\n",
    "cv_2 = participants[4:8]\n",
    "cv_3 = participants[8:12]\n",
    "cv_4 = participants[12:16]\n",
    "cv_5 = participants[16:]\n",
    "ML_trn_cv_1 = cv_2 + cv_3 + cv_4 + cv_5\n",
    "ML_tst_cv_1 = cv_1\n",
    "ML_trn_cv_2 = cv_1 + cv_3 + cv_4 + cv_5\n",
    "ML_tst_cv_2 = cv_2\n",
    "ML_trn_cv_3 = cv_1 + cv_2 + cv_4 + cv_5\n",
    "ML_tst_cv_3 = cv_3\n",
    "ML_trn_cv_4 = cv_1 + cv_2 + cv_3 + cv_5\n",
    "ML_tst_cv_4 = cv_4\n",
    "ML_trn_cv_5 = cv_1 + cv_2 + cv_3 + cv_4\n",
    "ML_tst_cv_5 = cv_5\n",
    "list_comb_agg = []\n",
    "list_comb_pad = []\n",
    "\n",
    "mode_list = ['keytime']\n",
    "cv_list = ['ML_trn','ML_dev','ML_trn_cv_1','ML_tst_cv_1','ML_trn_cv_2','ML_tst_cv_2',\n",
    "           'ML_trn_cv_3','ML_tst_cv_3','ML_trn_cv_4','ML_tst_cv_4','ML_trn_cv_5','ML_tst_cv_5']\n",
    "\n",
    "# create different data segments\n",
    "for cv in cv_list:\n",
    "    for mode in mode_list:\n",
    "        combcsv(globals()[cv], cv, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce5573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
