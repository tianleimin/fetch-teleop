{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069004b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# import the required modules\n",
    "from __future__ import print_function\n",
    "#from click import exceptions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "import statistics\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "#CUDA_VISIBLE_DEVICES=\"\"\n",
    "#tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import Input, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adamax, SGD, Adam\n",
    "from keras import initializers\n",
    "from keras.metrics import *\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize,LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pause = False\n",
    "\n",
    "# inference mode\n",
    "ep = 0\n",
    "csv_pre = 'data/auto_pre_handover.csv' # 5.5s without pause\n",
    "csv_post = 'data/auto_post_handover.csv' # 27.5s without pause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b77330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape panda.DataFrame to Keras style: (batch_size, time_step, nb_features)\n",
    "def reshape_data(data, n_prev):\n",
    "    docX = []\n",
    "    # add rows of 0s if there are too few rows for time step padding\n",
    "    df0 = pd.DataFrame(0.0, index=np.arange(n_prev), columns=data.columns)\n",
    "    if len(data) < n_prev:\n",
    "        data = pd.concat([data,df0])\n",
    "    # time step padding\n",
    "    for i in range(len(data)):\n",
    "        if i < (len(data)-n_prev):\n",
    "            docX.append(data[i:i+n_prev])\n",
    "        else: # the frames in the last window use the same context\n",
    "            docX.append(data[(len(data)-n_prev):len(data)])\n",
    "    alsX = np.array(docX)\n",
    "    return alsX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of the class labels\n",
    "def one_hot(labels):\n",
    "    labels_converted = []\n",
    "    for label in labels:\n",
    "        if label == 'LEFT':\n",
    "            label_converted = [1,0,0]\n",
    "        elif label == 'MIDDLE':\n",
    "            label_converted = [0,1,0]\n",
    "        elif label == 'RIGHT':\n",
    "            label_converted = [0,0,1]\n",
    "        labels_converted.append(label_converted)\n",
    "    labels_converted = np.asarray(labels_converted)\n",
    "    return labels_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct data\n",
    "def feature_read(df_file, feat_cols, label_cols):\n",
    "    # read in data\n",
    "    data = pd.read_csv(df_file, header=0)\n",
    "\n",
    "    # creating feature set\n",
    "    feat_cols_end = feat_cols + 100 # only use keypoints (x,y,z,conf) features\n",
    "    x_all = data.iloc[:, feat_cols:feat_cols_end]\n",
    "\n",
    "    # creating label arrays\n",
    "    y_otp = one_hot(data[label_cols[0]]) # OTP with 3 classes\n",
    "\n",
    "    return x_all, y_otp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf929e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the one-hot encoded predictions to origianl action labels\n",
    "def one_hot_rev(labels):\n",
    "    labels_converted = []\n",
    "    for label in labels:\n",
    "        if label == 0:\n",
    "            label_converted = 'LEFT'\n",
    "        elif label == 1:\n",
    "            label_converted = 'MIDDLE'\n",
    "        elif label == 2:\n",
    "            label_converted = 'RIGHT'\n",
    "        labels_converted.append(label_converted)\n",
    "    labels_converted = np.asarray(labels_converted)\n",
    "    return labels_converted\n",
    "\n",
    "# reverse the one-hot encoded predictions to True/False action labels\n",
    "def binary_rev(labels):\n",
    "    labels_converted = []\n",
    "    for label in labels:\n",
    "        if label == 0:\n",
    "            label_converted = False\n",
    "        elif label == 1:\n",
    "            label_converted = True\n",
    "        labels_converted.append(label_converted)\n",
    "    labels_converted = np.asarray(labels_converted)\n",
    "    return labels_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use saved model to continuously generate predictions of new data\n",
    "def inference(classifier = 'OTP', time_step = 5):\n",
    "    # load the saved model\n",
    "    file_log = 'inf_data/' + classifier + '_log.txt'\n",
    "    pred_f = 'inf_data/' + classifier + '_pred.csv'\n",
    "    model_name = 'inf_data/' + classifier + '_model.h5'\n",
    "    model = load_model(model_name)\n",
    "\n",
    "    # load data to be inferred on\n",
    "    inf_f = 'inf_data/PoseMonitor.csv'\n",
    "    inf_cols = 0 # OAK-D outcome only containing pose estimates\n",
    "\n",
    "    # read in data\n",
    "    df_inf = pd.read_csv(inf_f, header=0)\n",
    "    inf_cols_end = inf_cols + 100 # only use keypoints (x,y,z,conf) features\n",
    "    x_all_tst = df_inf.iloc[:, inf_cols:inf_cols_end]\n",
    "\n",
    "    # time step padding\n",
    "    X_tst = reshape_data(x_all_tst, time_step)\n",
    "\n",
    "    # reshape data for Conv2D\n",
    "    X_tst = X_tst.reshape(X_tst.shape[0],X_tst.shape[1],X_tst.shape[2],1)\n",
    "\n",
    "    # generate predictions\n",
    "\n",
    "    y_pred = model.predict(X_tst, verbose=0) # probabilities\n",
    "    y_pred_cat = np.zeros(y_pred.shape[0], dtype=int) # initialise array to store class labels\n",
    "\n",
    "    # adjustable prediction thresholds\n",
    "    if classifier == 'OTP':\n",
    "        thresholds = [0.4, 0.5, 0.1]\n",
    "    else:\n",
    "        thresholds = [0.6, 0.4]\n",
    "\n",
    "    # use custom probability threshold\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        for j in range(y_pred.shape[1]):\n",
    "            if y_pred[i,j] > thresholds[j]:\n",
    "                y_pred_cat[i] = j\n",
    "                break\n",
    "\n",
    "    # find the class with highest probability\n",
    "    # y_pred_cat = np.argmax(y_pred, axis=1) \n",
    "\n",
    "    # save predictions as a dataframe column\n",
    "    #df_pred = pd.DataFrame(columns=['handover status','arm status','base status'])\n",
    "    df_pred = pd.DataFrame(columns=['predicted'])\n",
    "\n",
    "    if classifier == 'OTP':\n",
    "        y_pred_cat_label = one_hot_rev(y_pred_cat) # switch from one-hot class labels to original lables\n",
    "    else:\n",
    "        y_pred_cat_label = binary_rev(y_pred_cat) # switch from binary one-hot class labels to original lables\n",
    "    df_pred['predicted'] = pd.Series(y_pred_cat_label)\n",
    "    # get majority class as segmet prediction\n",
    "    c_majority = df_pred['predicted'].value_counts()[:1].index.tolist()\n",
    "    l_majority = c_majority[0]\n",
    "    # print(y_pred)\n",
    "    # print(y_pred_cat)\n",
    "    # print(y_pred_cat_label)\n",
    "    print(f'Majority class predicted for this segment is: {l_majority}')\n",
    "\n",
    "    # save predictions to a csv file\n",
    "    #df_pred.to_csv(pred_f, index=False)\n",
    "\n",
    "    return l_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaad1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish name of csv to be replayed to ROS so auto.py (copy of replay_data.py) knows which files to use based on the ML inputs\n",
    "def ReplayDataMsg(replay_file):\n",
    "    # pub.publish(replay_file) # publish file name to topic\n",
    "    print(f'Replaying example segment: {replay_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9857462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use saved model to continuously generate predictions of new data\n",
    "while not pause:\n",
    "    # when to run the pre-handover segment\n",
    "    timeout = time.time() + 600 # (10min timeout)\n",
    "    while True:\n",
    "        start_ep = inference(classifier = 'BASE', time_step = 5)\n",
    "        if start_ep or (time.time() > timeout):\n",
    "            print(\"Executing pre-handover segment\\n\")\n",
    "            # execute the pre-handover segment\n",
    "            ReplayDataMsg(csv_pre)\n",
    "            # predict where to perform the handover when episode starts\n",
    "            prediction_otp = inference(classifier = 'OTP', time_step = 5)\n",
    "            csv_reach = 'data/auto_' + prediction_otp + '_OTP_reach.csv' # 5.0s without pause\n",
    "            csv_tuck = 'data/auto_' + prediction_otp + '_OTP_tuck.csv' # 5.1s without pause\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # when to run the participant handover reaching segment\n",
    "    while True:\n",
    "        start_OTP = inference(classifier = 'ARM_reach', time_step = 5)\n",
    "        if start_OTP or time.time() > timeout:\n",
    "            # update prediction of where to perform the handover at the start of object exchange if needed\n",
    "            prediction_otp = inference(classifier = 'OTP', time_step = 5)\n",
    "            csv_reach = 'data/auto_' + prediction_otp + '_OTP_reach.csv' # 5.0s without pause\n",
    "            csv_tuck = 'data/auto_' + prediction_otp + '_OTP_tuck.csv' # 5.1s without pause\n",
    "            # execute the participant handover reaching segment based on the predicted OTP\n",
    "            ReplayDataMsg(csv_reach)\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # when to run the participant handover tucking and the consequent post-handover segment\n",
    "    while True:\n",
    "        start_fin = inference(classifier = 'ARM_tuck', time_step = 5)\n",
    "        if start_fin or time.time() > timeout:\n",
    "            ReplayDataMsg(csv_tuck) # execute the participant handover tucking segment based on the predicted OTP\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    # execute the post-handover segment\n",
    "    ReplayDataMsg(csv_post)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    episode = [csv_pre, csv_reach, csv_tuck, csv_post] # 43.1s without pause\n",
    "    print(f'Finished episode No.{ep}, sequence: {episode}')\n",
    "    ep = ep + 1 # episode number counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9b7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
