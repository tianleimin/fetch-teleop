{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess collected csv data to use in RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read csv to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>time (s)</th>\n",
       "      <th>status</th>\n",
       "      <th>handover quality</th>\n",
       "      <th>handover type</th>\n",
       "      <th>arm status</th>\n",
       "      <th>base status</th>\n",
       "      <th>handover status</th>\n",
       "      <th>base (linear)</th>\n",
       "      <th>base (angular)</th>\n",
       "      <th>...</th>\n",
       "      <th>right_thumb (z)</th>\n",
       "      <th>right_thumb (confidence)</th>\n",
       "      <th>left_hip (x)</th>\n",
       "      <th>left_hip (y)</th>\n",
       "      <th>left_hip (z)</th>\n",
       "      <th>left_hip (confidence)</th>\n",
       "      <th>right_hip (x)</th>\n",
       "      <th>right_hip (y)</th>\n",
       "      <th>right_hip (z)</th>\n",
       "      <th>right_hip (confidence)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TO PARTICIPANT</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ROBOT TO HUMAN</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>TO PARTICIPANT</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ROBOT TO HUMAN</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>TO PARTICIPANT</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ROBOT TO HUMAN</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>TO PARTICIPANT</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ROBOT TO HUMAN</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>TO PARTICIPANT</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>ROBOT TO HUMAN</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>STATIONARY</td>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode  time (s)          status handover quality   handover type  \\\n",
       "0        0       0.0  TO PARTICIPANT          NEUTRAL  ROBOT TO HUMAN   \n",
       "1        0       0.1  TO PARTICIPANT          NEUTRAL  ROBOT TO HUMAN   \n",
       "2        0       0.2  TO PARTICIPANT          NEUTRAL  ROBOT TO HUMAN   \n",
       "3        0       0.3  TO PARTICIPANT          NEUTRAL  ROBOT TO HUMAN   \n",
       "4        0       0.4  TO PARTICIPANT          NEUTRAL  ROBOT TO HUMAN   \n",
       "\n",
       "   arm status base status handover status  base (linear)  base (angular)  ...  \\\n",
       "0  STATIONARY  STATIONARY          MIDDLE            0.0             0.0  ...   \n",
       "1  STATIONARY  STATIONARY          MIDDLE            0.0             0.0  ...   \n",
       "2  STATIONARY  STATIONARY          MIDDLE            0.0             0.0  ...   \n",
       "3  STATIONARY  STATIONARY          MIDDLE            0.0             0.0  ...   \n",
       "4  STATIONARY  STATIONARY          MIDDLE            0.0             0.0  ...   \n",
       "\n",
       "   right_thumb (z)  right_thumb (confidence)  left_hip (x)  left_hip (y)  \\\n",
       "0              0.0                       0.0           0.0           0.0   \n",
       "1              0.0                       0.0           0.0           0.0   \n",
       "2              0.0                       0.0           0.0           0.0   \n",
       "3              0.0                       0.0           0.0           0.0   \n",
       "4              0.0                       0.0           0.0           0.0   \n",
       "\n",
       "   left_hip (z)  left_hip (confidence)  right_hip (x)  right_hip (y)  \\\n",
       "0           0.0                    0.0            0.0            0.0   \n",
       "1           0.0                    0.0            0.0            0.0   \n",
       "2           0.0                    0.0            0.0            0.0   \n",
       "3           0.0                    0.0            0.0            0.0   \n",
       "4           0.0                    0.0            0.0            0.0   \n",
       "\n",
       "   right_hip (z)  right_hip (confidence)  \n",
       "0            0.0                     0.0  \n",
       "1            0.0                     0.0  \n",
       "2            0.0                     0.0  \n",
       "3            0.0                     0.0  \n",
       "4            0.0                     0.0  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data type of columns\n",
    "int_cols = ['episode']\n",
    "cat_cols = ['status', 'handover quality', 'handover type', 'arm status', 'base status', 'handover status']\n",
    "\n",
    "# load raw data\n",
    "participants = ['p1_2022-07-25', 'p2_2022-08-03', 'p3_2022-08-04', 'p4_2022-08-10', 'p5_2022-08-12', \n",
    "                'p6_2022-08-15', 'p7_2022-08-15', 'p8_2022-08-19', 'p9_2022-08-22', 'p10_2022-08-26', \n",
    "                'p11_2022-08-29', 'p12_2022-08-29', 'p13_2022-08-29', 'p14_2022-08-31', 'p15_2022-09-02', \n",
    "                'p16_2022-09-05', 'p17_2022-09-06', 'p18_2022-09-07', 'p19_2022-09-08', 'p20_2022-09-09']\n",
    "#for participant in participants:\n",
    "#    raw_data = 'data/ML/' + participant\n",
    "raw_data = 'data/ML/' + participants[0]\n",
    "\n",
    "# read csv into dataframe\n",
    "df = pd.read_csv((raw_data + '.csv'), header = 0)\n",
    "# specific data type of columns\n",
    "for column in df:\n",
    "    if column in int_cols:\n",
    "        df[column] = df[column].astype('int')\n",
    "    elif column in cat_cols:\n",
    "        df[column] = df[column].astype('category')\n",
    "    else:\n",
    "        df[column] = df[column].astype('float')\n",
    "\n",
    "# fill missing values in the manually entered handover quality and type columns\n",
    "df['handover quality'] = df['handover quality'].cat.add_categories('NEUTRAL')\n",
    "df['handover quality'].fillna('NEUTRAL', inplace =True)\n",
    "#df['handover type'] = df['handover type'].cat.add_categories('NEITHER')\n",
    "#df['handover type'].fillna('NEITHER', inplace =True) \n",
    "df['handover type'].fillna('ROBOT TO HUMAN', inplace =True) \n",
    "\n",
    "# df['handover quality'].dtype\n",
    "# df['handover type'][500:550]\n",
    "\n",
    "# preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIDDLE    14\n",
       "LEFT       9\n",
       "RIGHT      5\n",
       "Name: handover status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many of each type of handover is in a session\n",
    "# get step index within each episode\n",
    "#df['step'] = np.arange(len(df))\n",
    "#ep_start_step = df['step'][(np.diff(df['episode'].values, prepend=-1) > 0)].values\n",
    "#df_ep = df['handover status'][ep_start_step]\n",
    "#df_ep.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalise categorical emotion values and replace Fetch predictions when not facing participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise categorical emotion prediction values\n",
    "\n",
    "# categorical emotion values are network weights at output layer\n",
    "# the category label shown in GUI visualisation is the argmax of all 8 classes' weights (e.g., argmax(-8,-3) is -3)\n",
    "\n",
    "# normalise categorical emotion values to [0,1] by (60+x)/60 as the min is 60\n",
    "df.iloc[:,28:36] = df.iloc[:,28:36].apply(lambda x: (60+x)/ 60, axis=0) # OAK-D emotions\n",
    "df.iloc[:,38:46] = df.iloc[:,38:46].apply(lambda x: (60+x)/ 60, axis=0) # Fetch emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Fetch predictions with OAK-D predictions when it's not facing the participant\n",
    "\n",
    "# use status label to find when the robot is facing the participant\n",
    "facing_participant = ['TO PARTICIPANT', 'PARTICIPANT HANDOVER']\n",
    "not_facing_participant = ['TO OPERATOR', 'ROTATE TO OPERATOR', 'ROTATE TO PARTICIPANT', 'OPERATOR HANDOVER']\n",
    "emo_list = ['neutral','happy','sad','surprise','fear','disgust','anger','contempt','valence','arousal']\n",
    "\n",
    "#df1 = df.iloc[30020:30070]\n",
    "\n",
    "# replace Fetch emotions with OAK-D emotions\n",
    "for index, row in df.iterrows():\n",
    "    if row['status'] in not_facing_participant:\n",
    "        for emo in emo_list:\n",
    "            df.loc[index,str(emo+' (fetch)')] = df.loc[index,str(emo+' (global)')]\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. State observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state observations are OAK-D pose estimations in columns [48:148] and an added task progress (numerical)\n",
    "df['task progress'] = df['episode'] / max(df['episode'])\n",
    "\n",
    "# state observation in a new dataframe\n",
    "df_state = df.iloc[:,48:149]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions are categorical values in the 'arm status' and 'handover status' columns\n",
    "# 'base status' excluded for simplicity\n",
    "#df_action = df[['arm status', 'handover status']]\n",
    "\n",
    "# create a new column of action pairs\n",
    "df['action pair'] = df['arm status'].astype('str') + '+' + df['handover status'].astype('str')\n",
    "df['action pair'] = df['action pair'].astype('category')\n",
    "\n",
    "# coded actions\n",
    "action_encoding = {\n",
    "    'STATIONARY+MIDDLE' : 0,\n",
    "    'REACHING+MIDDLE' : 1,\n",
    "    'TUCKING+MIDDLE' : 2,\n",
    "    'STATIONARY+LEFT' : 3,\n",
    "    'REACHING+LEFT' : 4,\n",
    "    'TUCKING+LEFT' : 5,\n",
    "    'STATIONARY+RIGHT' : 6,\n",
    "    'REACHING+RIGHT' : 7,\n",
    "    'TUCKING+RIGHT' : 8,\n",
    "}\n",
    "df['action pair ID'] = df['action pair'].map(action_encoding)\n",
    "df['action pair ID'] = df['action pair ID'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotional reward\n",
    "\n",
    "# OAK-D categorical emotion sum\n",
    "df['emotion (global)'] = (df['neutral (global)'] + df['happy (global)'] + df['contempt (global)'])/3 \\\n",
    "                         - 0.2 * (df['sad (global)'] + df['surprise (global)'] + df['fear (global)'] \\\n",
    "                         + df['disgust (global)'] + df['anger (global)'])\n",
    "# Fetch categorical emotion sum\n",
    "df['emotion (fetch)'] = (df['neutral (fetch)'] + df['happy (fetch)'] + df['contempt (fetch)'])/3 \\\n",
    "                         - 0.2 * (df['sad (fetch)'] + df['surprise (fetch)'] + df['fear (fetch)'] \\\n",
    "                         + df['disgust (fetch)'] + df['anger (fetch)'])\n",
    "\n",
    "# combined emotional reward\n",
    "df['emotional reward'] = (df['emotion (global)'] + df['arousal (global)'] + df['valence (global)'] \\\n",
    "                        + df['emotion (fetch)'] + df['arousal (fetch)'] + df['valence (fetch)'])/6\n",
    "\n",
    "#print(max(df['emotional reward']))\n",
    "#print(min(df['emotional reward']))\n",
    "#print(df['emotional reward'].mean())\n",
    "#print(df['emotional reward'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handover quality reward\n",
    "# replacing categorical labels with values\n",
    "df['handover reward'] = df['handover quality'].map({'GOOD':1.0, 'BAD':-1.0, 'NEUTRAL':0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# combined reward\n",
    "df['combined reward'] = df['emotional reward'] + df['handover reward'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined reward but the handover quality is treated as an episode reward\n",
    "\n",
    "# get step index within each episode\n",
    "df['step'] = np.arange(len(df))\n",
    "ep_start_step = df['step'][(np.diff(df['episode'].values, prepend=-1) > 0)].values\n",
    "df['offset'] = ep_start_step[df['episode'].values]\n",
    "df.loc[:,'step'] = df['step'] - df['offset'] + 1\n",
    "# create a step progress fraction within each episode\n",
    "max_step_by_episode = df.groupby('episode')['step'].max().values\n",
    "df['fraction'] = df['step'] / np.repeat(max_step_by_episode, max_step_by_episode)\n",
    "# add handover quality reward scaled by step progress fraction so that later steps get more of the episodic reward\n",
    "df['combined reward async'] = df['emotional reward'] + df['handover reward'].astype('float')*df['fraction']\n",
    "#df[df['episode']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Only keeping columns needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping columns relevant\n",
    "df_time = df[['time (s)', 'episode', 'step']]\n",
    "df_tidy = pd.concat([df_time, df_state, df['action pair ID'], df['combined reward async']], axis=1)\n",
    "df_minerva = pd.concat([df['episode'], df_state, df['action pair ID'], df['combined reward async']], axis=1)\n",
    "\n",
    "#df_tidy[df['episode']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Use data segments when the robot is at work area to simplify learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State machine for overall robot status:\n",
    "# To participant -> Participant handover -> Rotate to operator ->\n",
    "# To operator -> Operator handover -> Rotate to participant\n",
    "\n",
    "# extract rows with 'status' = 'PARTICIPANT HANDOVER'\n",
    "df_seg = df.loc[df['status'] == 'PARTICIPANT HANDOVER']\n",
    "\n",
    "#print(df_seg['arm status'].value_counts())\n",
    "#print(df_seg['base status'].value_counts())\n",
    "#print(df_seg['handover quality'].value_counts())\n",
    "#print(df_seg['action pair ID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keeping columns relevant\n",
    "df_seg_time = df_seg[['time (s)', 'episode', 'step']]\n",
    "df_seg_state = df_seg.iloc[:,48:149]\n",
    "df_seg_action = df_seg['action pair ID']\n",
    "df_seg_reward = df_seg['combined reward async']\n",
    "df_seg_tidy = pd.concat([df_seg_time, df_seg_state, df_seg_action, df_seg_reward], axis=1)\n",
    "df_seg_minerva = pd.concat([df_seg['episode'], df_seg_state, df_seg_action, df_seg_reward], axis=1)\n",
    "\n",
    "#df_seg_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save preprocessed data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_f = raw_data + '_processed' + '.csv'\n",
    "#df_tidy.to_csv(processed_f, index=False)\n",
    "#df_seg_tidy.to_csv(processed_f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in the format of Minerva UI\n",
    "processed_minerva_f = raw_data + '_processed_minerva' + '.csv'\n",
    "new_header = ['episode','observation:0','observation:1','observation:2','observation:3','observation:4','observation:5','observation:6','observation:7','observation:8','observation:9','observation:10','observation:11','observation:12','observation:13','observation:14','observation:15','observation:16','observation:17','observation:18','observation:19','observation:20','observation:21','observation:22','observation:23','observation:24','observation:25','observation:26','observation:27','observation:28','observation:29','observation:30','observation:31','observation:32','observation:33','observation:34','observation:35','observation:36','observation:37','observation:38','observation:39','observation:40','observation:41','observation:42','observation:43','observation:44','observation:45','observation:46','observation:47','observation:48','observation:49','observation:50','observation:51','observation:52','observation:53','observation:54','observation:55','observation:56','observation:57','observation:58','observation:59','observation:60','observation:61','observation:62','observation:63','observation:64','observation:65','observation:66','observation:67','observation:68','observation:69','observation:70','observation:71','observation:72','observation:73','observation:74','observation:75','observation:76','observation:77','observation:78','observation:79','observation:80','observation:81','observation:82','observation:83','observation:84','observation:85','observation:86','observation:87','observation:88','observation:89','observation:90','observation:91','observation:92','observation:93','observation:94','observation:95','observation:96','observation:97','observation:98','observation:99','observation:100','action:0','reward']\n",
    "df_minerva.columns = new_header\n",
    "df_minerva.to_csv(processed_minerva_f, index=False)\n",
    "#df_seg_minerva.columns = new_header\n",
    "#df_seg_minerva.to_csv(processed_minerva_f, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Concatenate individually preprocessed csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = ['p1_2022-07-25', 'p2_2022-08-03', 'p3_2022-08-04', 'p4_2022-08-10', 'p5_2022-08-12', 'p6_2022-08-15', 'p7_2022-08-15']\n",
    "new_header = ['episode','observation:0','observation:1','observation:2','observation:3','observation:4','observation:5','observation:6','observation:7','observation:8','observation:9','observation:10','observation:11','observation:12','observation:13','observation:14','observation:15','observation:16','observation:17','observation:18','observation:19','observation:20','observation:21','observation:22','observation:23','observation:24','observation:25','observation:26','observation:27','observation:28','observation:29','observation:30','observation:31','observation:32','observation:33','observation:34','observation:35','observation:36','observation:37','observation:38','observation:39','observation:40','observation:41','observation:42','observation:43','observation:44','observation:45','observation:46','observation:47','observation:48','observation:49','observation:50','observation:51','observation:52','observation:53','observation:54','observation:55','observation:56','observation:57','observation:58','observation:59','observation:60','observation:61','observation:62','observation:63','observation:64','observation:65','observation:66','observation:67','observation:68','observation:69','observation:70','observation:71','observation:72','observation:73','observation:74','observation:75','observation:76','observation:77','observation:78','observation:79','observation:80','observation:81','observation:82','observation:83','observation:84','observation:85','observation:86','observation:87','observation:88','observation:89','observation:90','observation:91','observation:92','observation:93','observation:94','observation:95','observation:96','observation:97','observation:98','observation:99','observation:100','action:0','reward']\n",
    "list_comb = []\n",
    "combined_csv = 'data/combined_minerva.csv'\n",
    "offset = 0\n",
    "for participant in participants:\n",
    "    proc_data_each = 'data/' + participant + '_processed_minerva' + '.csv'\n",
    "    df_each = pd.read_csv(proc_data_each, header = 0)\n",
    "    # offset episode start count to continue after the previous csv\n",
    "    df_each['episode'] = df_each['episode'] + offset\n",
    "    offset = max(df_each['episode']) + 1\n",
    "    list_comb.append(df_each)\n",
    "df_comb = pd.concat(list_comb)\n",
    "df_comb.to_csv(combined_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
