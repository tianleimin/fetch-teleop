{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zisrGCcZUkdU"
   },
   "outputs": [],
   "source": [
    "# FACT HRC (FACT-support): example BLSTM model implementation\n",
    "# Attention-BLSTM emotion classification\n",
    "\n",
    "# import the required modules\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "import statistics\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "tf.config.experimental.set_visible_devices(devices=gpus[0], device_type='GPU')\n",
    "tf.config.experimental.set_memory_growth(device=gpus[0], enable=True)\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adamax\n",
    "from keras import initializers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize,LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Attention implemented by https://github.com/CyberZHG/keras-self-attention\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "# turn off the warnings, be careful when use this\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLSTM parameters\n",
    "batch_size = 32 # for estimating error gradient\n",
    "# number of total epochs to train the model\n",
    "nb_epoch = 20\n",
    "# optimization function\n",
    "opt_func = Adamax(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08) \n",
    "# to prevent over-fitting\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# number of features\n",
    "# nb_feat_time = 3 # ['time (s)', 'episode', 'step']\n",
    "# nb_feat_kp_cor = 75 # (x,y,z) of the 25 facial and upper body keypoints\n",
    "# nb_feat_kp_con = 25 # confidence of the facial and upper body keypoints\n",
    "# nb_feat_task = 1 # task progress\n",
    "# nb_feat_emo = 20 # categorical and arousal-valence for both cameras\n",
    "# nb_feat_rw = 3 # reward values: operator's rating, emotional reward, combined\n",
    "# nb_feat_all = nb_feat_time + nb_feat_kp_cor + nb_feat_kp_con + nb_feat_task + nb_feat_emo + nb_feat_rw\n",
    "\n",
    "# number of classes\n",
    "nb_class_base = 4 # {'STATIONARY', 'TO OPERATOR', 'ROTATING', 'TO PARTICIPANT'}\n",
    "nb_class_arm = 3 # {'STATIONARY', 'REACHING', 'TUCKING'}\n",
    "nb_class_otp = 3 # {'MIDDLE', 'LEFT', 'RIGHT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape panda.DataFrame to Keras style: (batch_size, time_step, nb_features)\n",
    "def reshape_data(data, n_prev):\n",
    "    docX = []\n",
    "    for i in range(len(data)):\n",
    "        if i < (len(data)-n_prev):\n",
    "            docX.append(data[i:i+n_prev])\n",
    "        else: # the frames in the last window use the same context\n",
    "            docX.append(data[(len(data)-n_prev):len(data)])\n",
    "    alsX = np.array(docX)\n",
    "    return alsX\n",
    "\n",
    "# one-hot encoding of the class labels\n",
    "def one_hot(labels, c_mode):\n",
    "    labels_converted = []\n",
    "    # labels in each class\n",
    "    if c_mode == 'arm':\n",
    "        for label in labels:\n",
    "            if label == 'STATIONARY':\n",
    "                label_converted = [1,0,0]\n",
    "            elif label == 'REACHING':\n",
    "                label_converted = [0,1,0]\n",
    "            elif label == 'TUCKING':\n",
    "                label_converted = [0,0,1]\n",
    "            labels_converted.append(label_converted)\n",
    "    elif c_mode == 'base':\n",
    "        for label in labels:\n",
    "            if label == 'STATIONARY':\n",
    "                label_converted = [1,0,0,0]\n",
    "            elif label == 'TO OPERATOR':\n",
    "                label_converted = [0,1,0,0]\n",
    "            elif label == 'ROTATING':\n",
    "                label_converted = [0,0,1,0]\n",
    "            elif label == 'TO PARTICIPANT':\n",
    "                label_converted = [0,0,0,1]\n",
    "            labels_converted.append(label_converted)\n",
    "    elif c_mode == 'otp':\n",
    "        for label in labels:\n",
    "            if label == 'LEFT':\n",
    "                label_converted = [1,0,0]\n",
    "            elif label == 'MIDDLE':\n",
    "                label_converted = [0,1,0]\n",
    "            elif label == 'RIGHT':\n",
    "                label_converted = [0,0,1]\n",
    "            labels_converted.append(label_converted)\n",
    "    labels_converted = np.asarray(labels_converted)\n",
    "    return labels_converted\n",
    "\n",
    "# construct feature sets\n",
    "def feature_ab(df_file, c_mode):\n",
    "    # read in data\n",
    "    data = pd.read_csv(df_file, header=0)\n",
    "    \n",
    "    # creating feature sets for ablation studies\n",
    "    x_all = data.iloc[:,:127]\n",
    "    # drop S1 handover episodes in training set: episodes [0,1,2,3]\n",
    "    no_S1_data = data[data.episode > 3]\n",
    "    X_no_S1 = no_S1_data.iloc[:,:127]\n",
    "    # for ablation studies\n",
    "    x_no_time = data.iloc[:,3:127]\n",
    "    x_no_rw = data.iloc[:,3:124]\n",
    "    x_no_emo = data.iloc[:,23:124]\n",
    "    x_no_tp = data.iloc[:,23:123]\n",
    "    data = data[data.columns.drop(list(data.filter(regex='(confidence)')))]\n",
    "    x_no_conf = data.iloc[:,23:98]\n",
    "    \n",
    "    # creating one-hot encoded label arrays\n",
    "    if c_mode == 'arm':\n",
    "        y = one_hot(data['arm status'], c_mode)\n",
    "        y_no_S1 = one_hot(no_S1_data['arm status'], c_mode)\n",
    "    elif c_mode == 'base':\n",
    "        y = one_hot(data['base status'], c_mode)\n",
    "        y_no_S1 = one_hot(no_S1_data['base status'], c_mode)\n",
    "    elif c_mode == 'otp':\n",
    "        y = one_hot(data['handover status'], c_mode)\n",
    "        y_no_S1 = one_hot(no_S1_data['handover status'], c_mode)\n",
    "    \n",
    "    return x_all, x_no_time, x_no_rw, x_no_emo, x_no_tp, x_no_conf, x_no_S1, y, y_no_S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the BLSTM model with attention\n",
    "def attBLSTM(lstm_size, attention_width, nb_class, opt_func):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units=lstm_size[0], return_sequences=True))) # BLSTM layer 1\n",
    "    model.add(Bidirectional(LSTM(units=lstm_size[1], return_sequences=True))) # BLSTM layer 2\n",
    "    model.add(Bidirectional(LSTM(units=lstm_size[2], return_sequences=True))) # BLSTM layer 3\n",
    "    model.add(SeqSelfAttention(attention_width=attention_width, attention_activation='sigmoid')) # attention layer\n",
    "    model.add(Dense(units=nb_class, activation='softmax')) # output layer, predict emotion dimensions seperately\n",
    "    return model\n",
    "\n",
    "# evaluate model performance and print results\n",
    "def model_eval(X_tst, Y_tst, log_f, batch_size=32):\n",
    "    model.evaluate(X_tst, Y_tst, batch_size=batch_size)\n",
    "    tst_pred = model.predict(X_tst)\n",
    "    y_tst_non_category = [ np.argmax(t[0]) for t in Y_tst ]\n",
    "    y_tst_predict_non_category = [ np.argmax(t[0]) for t in tst_pred ]\n",
    "    print('\\nConfusion Matrix on test set')\n",
    "    print(confusion_matrix(y_tst_non_category, y_tst_predict_non_category))\n",
    "    tst_f1 = f1_score(y_tst_non_category, y_tst_predict_non_category, average='weighted')\n",
    "    tst_f1_unweighted = f1_score(y_tst_non_category, y_tst_predict_non_category, average='macro')\n",
    "    print('\\nWeighted F1-score on test set:', tst_f1)\n",
    "    print('\\nUnweighted F1-score on test set:', tst_f1_unweighted)\n",
    "    with open(log_f, 'a') as logfile:\n",
    "        logfile.write('\\nConfusion Matrix on test set\\n')\n",
    "        np.savetxt(logfile, confusion_matrix(y_tst_non_category, y_tst_predict_non_category))\n",
    "        logfile.write('\\nWeighted F1-score on test set: %s' % tst_f1)\n",
    "        logfile.write('\\nUneighted F1-score on test set: %s' % tst_f1_unweighted)\n",
    "        \n",
    "    return tst_f1, tst_f1_unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode control for feature set and class\n",
    "time_stamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "c_mode_list = ['arm', 'base', 'otp'] # class\n",
    "f_mode_list = ['all', 'no_time', 'no_rw', 'no_emo', 'no_tp', 'no_conf'] # ablation\n",
    "# f_mode_list = ['all', 'no_time', 'no_rw', 'no_emo', 'no_tp', 'no_conf', 'no_S1'] # test removing S1 data\n",
    "cv_list = ['cv_1.csv', 'cv_2.csv', 'cv_3.csv', 'cv_4.csv', 'cv_5.csv'] # 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ablation study with the best model parameters\n",
    "# loop by each class\n",
    "for c_mode in c_mode_list:\n",
    "    file_log = 'exp_cv/logs/LSTM_' + c_mode + '_log_' + time_stamp + '.txt'\n",
    "    # best parameter combo resulted from grid search on dev set\n",
    "    if c_mode == 'arm':\n",
    "        para = [1,[16,8,4],2]\n",
    "    elif c_mode == 'base':\n",
    "        para = [5,[64,32,16],1]\n",
    "    elif c_mode == 'otp':\n",
    "        para = [10,[64,32,16],1]\n",
    "    \n",
    "    # loop by feature set\n",
    "    for f_mode in f_mode_list:\n",
    "        model_dir = 'exp_cv/models/LSTM/' + c_mode + '/' + f_mode + '/'\n",
    "        # compute cv average\n",
    "        f1_weighted = []\n",
    "        f1_unweighted = []\n",
    "        f1_weighted_average = 0.0\n",
    "        f1_unweighted_average = 0.0\n",
    "        \n",
    "        # loop by cross-validation fold\n",
    "        for cv in cv_list:\n",
    "            # input data files\n",
    "            df_file_trn = 'data/ML/combined_ML_trn_' + cv\n",
    "            df_file_tst = 'data/ML/combined_ML_tst_' + cv\n",
    "            \n",
    "            # information about the run\n",
    "            print('\\n====================================')\n",
    "            print('\\nclass = %s, features = %s, fold = %s\\ntime_step = %s, [h1,h2,h3] = %s, attention = %s\\n' \n",
    "                  % (c_mode, f_mode, cv, para[0], para[1], para[2]))\n",
    "            print('------------------\\n')\n",
    "            with open(file_log, 'a') as outfile:\n",
    "                outfile.write('\\n====================================')\n",
    "                outfile.write('\\nclass = %s, features = %s, fold = %s\\ntime_step = %s, [h1,h2,h3] = %s, attention = %s\\n' \n",
    "                              % (c_mode, f_mode, cv, para[0], para[1], para[2]))\n",
    "                outfile.write('------------------\\n')\n",
    "            \n",
    "            # read in data\n",
    "            x_all_trn, x_no_time_trn, x_no_rw_trn, x_no_emo_trn, x_no_tp_trn, x_no_conf_trn, x_no_S1_trn, y_trn, y_no_S1_trn = \n",
    "            feature_ab(df_file_trn, c_mode)\n",
    "            x_all_tst, x_no_time_tst, x_no_rw_tst, x_no_emo_tst, x_no_tp_tst, x_no_conf_tst, x_no_S1_tst, y_tst, y_no_S1_tst = \n",
    "            feature_ab(df_file_tst, c_mode)\n",
    "            \n",
    "            # time step padding\n",
    "            X_trn = reshape_data(globals()['x_'+str(f_mode)+'_trn'], para[0])\n",
    "            X_tst = reshape_data(globals()['x_'+str(f_mode)+'_tst'], para[0])\n",
    "            if f_mode == 'no_S1':\n",
    "                Y_trn = reshape_data(y_no_S1_trn, para[0])\n",
    "                # Y_tst = reshape_data(y_no_S1_tst, para[0]) # drop S1 in test set too\n",
    "                Y_tst = reshape_data(y_tst, para[0])\n",
    "            else:\n",
    "                Y_trn = reshape_data(y_trn, para[0])\n",
    "                Y_tst = reshape_data(y_tst, para[0])\n",
    "            \n",
    "            # training\n",
    "            model = attBLSTM(para[1], para[2], globals()['nb_class_'+str(c_mode)], opt_func)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt_func, metrics=['categorical_accuracy'])\n",
    "            model.fit(X_trn, Y_trn, batch_size=batch_size, epochs=nb_epoch, \n",
    "                      validation_split=0.05, callbacks=[early_stopping], verbose=2)\n",
    "            \n",
    "            # evaluation\n",
    "            tst_f1, tst_f1_unweighted = model_eval(X_tst, Y_tst, file_log, batch_size=batch_size)\n",
    "            f1_weighted.append(tst_f1)\n",
    "            f1_unweighted.append(tst_f1_unweighted)\n",
    "            model.save(model_dir)\n",
    "            \n",
    "        # calculate CV average\n",
    "        f1_weighted_average = statistics.mean(f1_weighted)\n",
    "        f1_unweighted_average = statistics.mean(f1_unweighted)\n",
    "        print('\\n****** CV Summary ******\\n')\n",
    "        print('class = %s, features = %s, F1 (weighted) = %s, F1 (unweighted) = %s\\n' \n",
    "              % (c_mode, f_mode, f1_weighted_average, f1_unweighted_average))\n",
    "        print('====================================\\n')\n",
    "        with open(file_log, 'a') as outfile:\n",
    "            outfile.write('\\n****** CV Summary ******\\n')\n",
    "            outfile.write('class = %s, features = %s, F1 (weighted) = %s, F1 (unweighted) = %s\\n' \n",
    "                          % (c_mode, f_mode, f1_weighted_average, f1_unweighted_average))\n",
    "            outfile.write('====================================\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para_list = []\n",
    "# tst_pred_list = []\n",
    "# f1_list = []\n",
    "# count = 1\n",
    "\n",
    "# # parameters to be investigated in grid seearch\n",
    "# time_steps = [1,5,10]  # input history to include: [1,5,10]\n",
    "# lstm_sizes = [[16,8,4],[32,16,8],[64,32,16]] # number of neurons in the BLSTM layers: [[16,8,4],[32,16,8],[64,32,16]]\n",
    "# attention_widths = [1,2,4] # width of the local context for the attention layer: [1,2,4]\n",
    "\n",
    "# grid_search = False\n",
    "\n",
    "# # Grid search on dev set\n",
    "# if grid_search:\n",
    "#     for time_step in time_steps:\n",
    "#         # pad data\n",
    "#         X_trn = reshape_data(globals()['x_'+str(f_mode)+'_trn'], time_step)\n",
    "#         X_dev = reshape_data(globals()['x_'+str(f_mode)+'_dev'], time_step)\n",
    "#         Y_trn = reshape_data(globals()['y_'+str(c_mode)+'_trn'], time_step)\n",
    "#         Y_dev = reshape_data(globals()['y_'+str(c_mode)+'_dev'], time_step)\n",
    "#         for lstm_size in lstm_sizes:\n",
    "#             for attention_width in attention_widths:\n",
    "#                 para_list.append([time_step, lstm_size, attention_width]) # save parameter set\n",
    "#                 print('\\n================================ No. %s of 27 ========================================' % count)\n",
    "#                 print('\\nParameters: time_step = %s, [h1, h2, h3] = %s, attention_width = %s\\n' \n",
    "#                       % (time_step, lstm_size, attention_width))\n",
    "#                 # build model with given parameters\n",
    "#                 model = attBLSTM(lstm_size, attention_width, globals()['nb_class_'+str(c_mode)], opt_func)\n",
    "#                 # compile the model\n",
    "#                 model.compile(loss='categorical_crossentropy', optimizer=opt_func, metrics=['categorical_accuracy'])\n",
    "#                 # training the model\n",
    "#                 model.fit(X_trn, Y_trn, batch_size=batch_size, epochs=nb_epoch, \n",
    "#                           validation_split=0.05, callbacks=[early_stopping], verbose=2)\n",
    "#                 # evaluation\n",
    "#                 model.evaluate(X_dev, Y_dev, batch_size=batch_size)\n",
    "#                 # save model\n",
    "#                 model_f = model_dir + str(count)\n",
    "#                 model.save(model_f)\n",
    "\n",
    "#                 # save predictions\n",
    "#                 tst_pred = model.predict(X_dev)\n",
    "#                 tst_pred_list.append(tst_pred) # save predictions\n",
    "\n",
    "#                 # print confusion matrix\n",
    "#                 y_test_non_category = [ np.argmax(t[0]) for t in Y_dev ]\n",
    "#                 y_predict_non_category = [ np.argmax(t[0]) for t in tst_pred ]\n",
    "#                 print('Confusion Matrix on dev set')\n",
    "#                 print(confusion_matrix(y_test_non_category, y_predict_non_category))\n",
    "#                 tst_f1 = f1_score(y_test_non_category, y_predict_non_category, average='weighted')\n",
    "#                 f1_list.append(tst_f1) # save f1 score\n",
    "#                 print('Weighted F1-score on dev set:', tst_f1)\n",
    "#                 # print grid search log\n",
    "#                 with open(file_log, 'a') as logfile:\n",
    "#                     logfile.write('\\n================================ No. %s of 27 ========================================\\n' % count)\n",
    "#                     logfile.write('F1 = %s; Parameters: time_step = %s, [h1, h2, h3] = %s, attention_width = %s\\n' \n",
    "#                                   % (tst_f1, time_step, lstm_size, attention_width))\n",
    "#                     logfile.write('Confusion Matrix on dev set\\n')\n",
    "#                     np.savetxt(logfile, confusion_matrix(y_test_non_category, y_predict_non_category))          \n",
    "#                 count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the best parameter set\n",
    "# best = f1_list.index(max(f1_list)) # find the highest F1 score\n",
    "# best_count = best + 1\n",
    "# result = f1_list[best]\n",
    "# para = para_list[best]\n",
    "# # prediction = tst_pred_list[best]\n",
    "# print('Best Run at No.%s; F1 = %s; Parameters: time_step = %s, [h1,h2,h3] = %s, attention_width = %s\\n' \n",
    "#       % (best_count, result, para[0], para[1], para[2]))\n",
    "\n",
    "# with open(file_out, 'a') as outfile:\n",
    "#     outfile.write('Best Run at No.%s; F1 = %s; Parameters: time_step = %s, [h1,h2,h3] = %s, attention_width = %s\\n' \n",
    "#                    % (best_count, result, para[0], para[1], para[2]))\n",
    "\n",
    "# # save predictions in case of significance test\n",
    "# # with open(file_pred, 'a') as predfile:\n",
    "# #     for pred in prediction:\n",
    "# #         indi_pred = []\n",
    "# #         indi_pred = pred[0] # reform the seq prediction to individual samples\n",
    "# #         row = ', '.join(map(str, indi_pred))\n",
    "# #         predfile.write('%s\\n' % row)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
