====== explanation and value ranges of all 148 columns in the raw csv data ======
col[0]: handover episode count [0,30)
col[1]: time step at 0.1 second resolution [0,3700.0)

col[2]: action category {'TO PARTICIPANT', 'TO OPERATOR', 'ROTATE TO OPERATOR', 'ROTATE TO PARTICIPANT', 'PARTICIPANT HANDOVER', 'OPERATOR HANDOVER'}
col[3]: handover quality rating {'GOOD', 'BAD', 'N/A'} # missing values ('N/A') replaced with 'NEUTRAL'
col[4]: handover type {'HUMAN TO ROBOT', 'ROBOT TO HUMAN', 'BOTH', 'N/A'} # missing values ('N/A') replaced with 'NEITHER'
col[5]: arm status {'STATIONARY', 'REACHING', 'TUCKING'}
col[6]: base status {'STATIONARY', 'TO OPERATOR', 'ROTATING', 'TO PARTICIPANT'}
col[7]: handover position type {'MIDDLE', 'LEFT', 'RIGHT'}

col[8]: base velocity (linear) [-1,1]
col[9]: base velocity (angular) [-1,1]
col[10]: arm velocity (linear for trajectory following) [-1,1]
col[11]: base coordinate x (-2.5,0]
col[12]: base coordinate y [0,15)
col[13]: based theta (-3.142,3.142)
col[14]: gripper coordinate x [0,0.9)
col[15]: gripper coordinate y (-0.4,0.4)
col[16]: gripper coordinate z [0,1)
col[17]: gripper angle qx (-0.01,0.01)
col[18]: gripper angle qy (-0.01,0.01)
col[19]: gripper angle qz [-1,1]
col[20]: gripper angle qw [-1,1]

col[21]: handover goal coordinate x {middle = 0.85, left = 0.85, right = 0.85}
col[22]: handover goal coordinate y {middle = 0, left = 0.35, right = -0.35}
col[23]: handover goal coordinate z {middle = 0.9, left = 0.9, right = 0.9}
col[24]: handover goal angle qx {middle = 0, left = 0, right = 0}
col[25]: handover goal angle qy {middle = 0, left = 0, right = 0}
col[26]: handover goal angle qz {middle = 0, left = -0.2474, right = -0.2474}
col[27]: handover goal angle qw {middle = 1, left = 0.9689, right = 0.9689}

# categorical emotion values are network weights at output layer
# the category label shown in GUI visualisation is the argmax of all 8 classes' weights (argmax(-8,-3) gives -3)
# in data preprocessing the categorical emotion weights are normalised as (60+x)/60
col[28]: OAK-D emotion prediction for neutral (-60,0]
col[29]: OAK-D emotion prediction for happy (-60,0]
col[30]: OAK-D emotion prediction for sad (-60,0]
col[31]: OAK-D emotion prediction for surprise (-60,0]
col[32]: OAK-D emotion prediction for fear (-60,0]
col[33]: OAK-D emotion prediction for disgust (-60,0]
col[34]: OAK-D emotion prediction for anger (-60,0]
col[35]: OAK-D emotion prediction for contempt (-60,0]
col[36]: OAK-D emotion prediction for valence [-1,1]
col[37]: OAK-D emotion prediction for arousal [-1,1]

col[38]: FETCH emotion prediction for neutral (-60,0]
col[39]: FETCH emotion prediction for happy (-60,0]
col[40]: FETCH emotion prediction for sad (-60,0]
col[41]: FETCH emotion prediction for surprise (-60,0]
col[42]: FETCH emotion prediction for fear (-60,0]
col[43]: FETCH emotion prediction for disgust (-60,0]
col[44]: FETCH emotion prediction for anger (-60,0]
col[45]: FETCH emotion prediction for contempt (-60,0]
col[46]: FETCH emotion prediction for valence [-1,1]
col[47]: FETCH emotion prediction for arousal [-1,1]

col[48]: OAK-D pose estimation for nose x [-1,1]
col[49]: OAK-D pose estimation for nose y [-1,1]
col[50]: OAK-D pose estimation for nose z [-1,1]
col[51]: OAK-D pose estimation for nose confidence [0,1]

col[52]: OAK-D pose estimation for left_eye_inner x [-1,1]
col[53]: OAK-D pose estimation for left_eye_inner y [-1,1]
col[54]: OAK-D pose estimation for left_eye_inner z [-1,1]
col[55]: OAK-D pose estimation for left_eye_inner confidence [0,1]
col[56]: OAK-D pose estimation for left_eye x [-1,1]
col[57]: OAK-D pose estimation for left_eye y [-1,1]
col[58]: OAK-D pose estimation for left_eye z [-1,1]
col[59]: OAK-D pose estimation for left_eye confidence [0,1]
col[60]: OAK-D pose estimation for left_eye_outer x [-1,1]
col[61]: OAK-D pose estimation for left_eye_outer y [-1,1]
col[62]: OAK-D pose estimation for left_eye_outer z [-1,1]
col[63]: OAK-D pose estimation for left_eye_outer confidence [0,1]

col[64]: OAK-D pose estimation for right_eye_inner x [-1,1]
col[65]: OAK-D pose estimation for right_eye_inner y [-1,1]
col[66]: OAK-D pose estimation for right_eye_inner z [-1,1]
col[67]: OAK-D pose estimation for right_eye_inner confidence [0,1]
col[68]: OAK-D pose estimation for right_eye x [-1,1]
col[69]: OAK-D pose estimation for right_eye y [-1,1]
col[70]: OAK-D pose estimation for right_eye z [-1,1]
col[71]: OAK-D pose estimation for right_eye confidence [0,1]
col[72]: OAK-D pose estimation for right_eye_outer x [-1,1]
col[73]: OAK-D pose estimation for right_eye_outer y [-1,1]
col[74]: OAK-D pose estimation for right_eye_outer z [-1,1]
col[75]: OAK-D pose estimation for right_eye_outer confidence [0,1]

col[76]: OAK-D pose estimation for left_ear x [-1,1]
col[77]: OAK-D pose estimation for left_ear y [-1,1]
col[78]: OAK-D pose estimation for left_ear z [-1,1]
col[79]: OAK-D pose estimation for left_ear confidence [0,1]
col[80]: OAK-D pose estimation for right_ear x [-1,1]
col[81]: OAK-D pose estimation for right_ear y [-1,1]
col[82]: OAK-D pose estimation for right_ear z [-1,1]
col[83]: OAK-D pose estimation for right_ear confidence [0,1]

col[84]: OAK-D pose estimation for mouth_left x [-1,1]
col[85]: OAK-D pose estimation for mouth_left y [-1,1]
col[86]: OAK-D pose estimation for mouth_left z [-1,1]
col[87]: OAK-D pose estimation for mouth_left confidence [0,1]
col[88]: OAK-D pose estimation for mouth_right x [-1,1]
col[89]: OAK-D pose estimation for mouth_right y [-1,1]
col[90]: OAK-D pose estimation for mouth_right z [-1,1]
col[91]: OAK-D pose estimation for mouth_right confidence [0,1]

col[92]: OAK-D pose estimation for left_shoulder x [-1,1]
col[93]: OAK-D pose estimation for left_shoulder y [-1,1]
col[94]: OAK-D pose estimation for left_shoulder z [-1,1]
col[95]: OAK-D pose estimation for left_shoulder confidence [0,1]
col[96]: OAK-D pose estimation for right_shoulder x [-1,1]
col[97]: OAK-D pose estimation for right_shoulder y [-1,1]
col[98]: OAK-D pose estimation for right_shoulder z [-1,1]
col[99]: OAK-D pose estimation for right_shoulder confidence [0,1]

col[100]: OAK-D pose estimation for left_elbow x [-1,1]
col[101]: OAK-D pose estimation for left_elbow y [-1,1]
col[102]: OAK-D pose estimation for left_elbow z [-1,1]
col[103]: OAK-D pose estimation for left_elbow confidence [0,1]
col[104]: OAK-D pose estimation for right_elbow x [-1,1]
col[105]: OAK-D pose estimation for right_elbow y [-1,1]
col[106]: OAK-D pose estimation for right_elbow z [-1,1]
col[107]: OAK-D pose estimation for right_elbow confidence [0,1]

col[108]: OAK-D pose estimation for left_wrist x [-1,1]
col[109]: OAK-D pose estimation for left_wrist y [-1,1]
col[110]: OAK-D pose estimation for left_wrist z [-1,1]
col[111]: OAK-D pose estimation for left_wrist confidence [0,1]
col[112]: OAK-D pose estimation for right_wrist x [-1,1]
col[113]: OAK-D pose estimation for right_wrist y [-1,1]
col[114]: OAK-D pose estimation for right_wrist z [-1,1]
col[115]: OAK-D pose estimation for right_wrist confidence [0,1]

col[116]: OAK-D pose estimation for left_pinky x [-1,1]
col[117]: OAK-D pose estimation for left_pinky y [-1,1]
col[118]: OAK-D pose estimation for left_pinky z [-1,1]
col[119]: OAK-D pose estimation for left_pinky confidence [0,1]
col[120]: OAK-D pose estimation for right_pinky x [-1,1]
col[121]: OAK-D pose estimation for right_pinky y [-1,1]
col[122]: OAK-D pose estimation for right_pinky z [-1,1]
col[123]: OAK-D pose estimation for right_pinky confidence [0,1]

col[124]: OAK-D pose estimation for left_index x [-1,1]
col[125]: OAK-D pose estimation for left_index y [-1,1]
col[126]: OAK-D pose estimation for left_index z [-1,1]
col[127]: OAK-D pose estimation for left_index confidence [0,1]
col[128]: OAK-D pose estimation for right_index x [-1,1]
col[129]: OAK-D pose estimation for right_index y [-1,1]
col[130]: OAK-D pose estimation for right_index z [-1,1]
col[131]: OAK-D pose estimation for right_index confidence [0,1]

col[132]: OAK-D pose estimation for left_thumb x [-1,1]
col[133]: OAK-D pose estimation for left_thumb y [-1,1]
col[134]: OAK-D pose estimation for left_thumb z [-1,1]
col[135]: OAK-D pose estimation for left_thumb confidence [0,1]
col[136]: OAK-D pose estimation for right_thumb x [-1,1]
col[137]: OAK-D pose estimation for right_thumb y [-1,1]
col[138]: OAK-D pose estimation for right_thumb z [-1,1]
col[139]: OAK-D pose estimation for right_thumb confidence [0,1]

col[140]: OAK-D pose estimation for left_hip x [-1,1]
col[141]: OAK-D pose estimation for left_hip y [-1,1]
col[142]: OAK-D pose estimation for left_hip z [-1,1]
col[143]: OAK-D pose estimation for left_hip confidence [0,1]
col[144]: OAK-D pose estimation for right_hip x [-1,1]
col[145]: OAK-D pose estimation for right_hip y [-1,1]
col[146]: OAK-D pose estimation for right_hip z [-1,1]
col[147]: OAK-D pose estimation for right_hip confidence [0,1]

====== header row copy ======
['episode', 'time (s)', 'status', 'handover quality', 'handover type', 'arm status', 'base status', 'handover status', 'base (linear)', 'base (angular)', 'arm (linear)', 'base (x)', 'base (y)', 'base (theta)', 'gripper (x)', 'gripper (y)', '|gripper (z)', ' gripper (qx)|', 'gripper (qy)', 'gripper (qz)', 'gripper (qw)', 'handover_goal (x)', 'handover_goal (y)', '|handover_goal (z)', ' handover_goal (qx)|', 'handover_goal (qy)', 'handover_goal (qz)', 'handover_goal (qw)', 'neutral (global)', 'happy (global)', 'sad (global)', 'surprise (global)', 'fear (global)', 'disgust (global)', 'anger (global)', 'contempt (global)', 'valence (global)', 'arousal (global)', 'neutral (fetch)', 'happy (fetch)', 'sad (fetch)', 'surprise (fetch)', 'fear (fetch)', 'disgust (fetch)', 'anger (fetch)', 'contempt (fetch)', 'valence (fetch)', 'arousal (fetch)', 'nose (x)', 'nose (y)', 'nose (z)', 'nose (confidence)', 'left_eye_inner (x)', 'left_eye_inner (y)', 'left_eye_inner (z)', 'left_eye_inner (confidence)', 'left_eye (x)', 'left_eye (y)', 'left_eye (z)', 'left_eye (confidence)', 'left_eye_outer (x)', 'left_eye_outer (y)', 'left_eye_outer (z)', 'left_eye_outer (confidence)', 'right_eye_inner (x)', 'right_eye_inner (y)', 'right_eye_inner (z)', 'right_eye_inner (confidence)', 'right_eye (x)', 'right_eye (y)', 'right_eye (z)', 'right_eye (confidence)', 'right_eye_outer (x)', 'right_eye_outer (y)', 'right_eye_outer (z)', 'right_eye_outer (confidence)', 'left_ear (x)', 'left_ear (y)', 'left_ear (z)', 'left_ear (confidence)', 'right_ear (x)', 'right_ear (y)', 'right_ear (z)', 'right_ear (confidence)', 'mouth_left (x)', 'mouth_left (y)', 'mouth_left (z)', 'mouth_left (confidence)', 'mouth_right (x)', 'mouth_right (y)', 'mouth_right (z)', 'mouth_right (confidence)', 'left_shoulder (x)', 'left_shoulder (y)', 'left_shoulder (z)', 'left_shoulder (confidence)', 'right_shoulder (x)', 'right_shoulder (y)', 'right_shoulder (z)', 'right_shoulder (confidence)', 'left_elbow (x)', 'left_elbow (y)', 'left_elbow (z)', 'left_elbow (confidence)', 'right_elbow (x)', 'right_elbow (y)', 'right_elbow (z)', 'right_elbow (confidence)', 'left_wrist (x)', 'left_wrist (y)', 'left_wrist (z)', 'left_wrist (confidence)', 'right_wrist (x)', 'right_wrist (y)', 'right_wrist (z)', 'right_wrist (confidence)', 'left_pinky (x)', 'left_pinky (y)', 'left_pinky (z)', 'left_pinky (confidence)', 'right_pinky (x)', 'right_pinky (y)', 'right_pinky (z)', 'right_pinky (confidence)', 'left_index (x)', 'left_index (y)', 'left_index (z)', 'left_index (confidence)', 'right_index (x)', 'right_index (y)', 'right_index (z)', 'right_index (confidence)', 'left_thumb (x)', 'left_thumb (y)', 'left_thumb (z)', 'left_thumb (confidence)', 'right_thumb (x)', 'right_thumb (y)', 'right_thumb (z)', 'right_thumb (confidence)', 'left_hip (x)', 'left_hip (y)', 'left_hip (z)', 'left_hip (confidence)', 'right_hip (x)', 'right_hip (y)', 'right_hip (z)', 'right_hip (confidence)']
